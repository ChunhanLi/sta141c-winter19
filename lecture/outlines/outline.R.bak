## ## Announcements

## - The homework took me between 30 minutes to 1 hour to run in serial.
##   Budget your time accordingly to complete this assignment.
## - Memory usage plot
## - Office hours today in 4th floor MSB
## - Mid quarter inquiry scheduled for Thursday, Feb 7th.
##   Please bring laptops.

## ## Review

## Last class I introduced debugging techniques.

## Call `debug` on a function to enter the browser when that function is called.

debug(zapsmall)

x = c(1, 1e-12)

zapsmall(x)

undebug(zapsmall)

## Set `options(error = recover)` to enter the debugger and directly examine the state of the program when it failed.

options(error = recover)

zapsmall(x, digits = numeric())

## ## Introduction to Parallelism

## (Slides)[https://docs.google.com/presentation/d/1qmnBM6hwl-nu2wf9sPF8pIxWEtlPd-6O2DH7aq0CZWU/edit?usp=sharing]

## Parallelism that works
















## __Question__: Why use a recommended package?
















## Some working definitions:
## - manager: the process that assigns and collect work
## - worker / node: the process that performs the work
## - cluster: the collection of worker nodes





































































clusterSplit(cls, x)






































































## Let's check.

clusterCall(cls, ls, envir = globalenv())

























## The general problem is to synchronize state so that the workers will behave as we want them to.
## For example, we might load a library locally.

library(tm)
















## Will the workers load the tm package if the manager loads it?
















## Side note: I'm mentioning meta-techniques here: pose a small question that will strengthen your mental model of how this all works.

parLapply(cls, strings, preprocess3)

















## `clusterEvalQ` evaluates arbitrary code on the cluster:
## Now the code above should work.

















## The code is exactly the same.
## It will only run if the workers are ready.
## Furthermore, it will only give you the right answer if all the objects are as you expect them to be.
















## One possible approach to synchronization is to just send everything to the workers.
## What's wrong with this?
















## What's an easy way to synchronize?
















## Write a script!

















## Scratch

library(parallel)

cls = makeCluster(2L, type = "PSOCK")

cls
## This shows what kind of cluster this is, and where it is.

## When we're done using the cluster, best practice is to turn it off.
## If we forget, then R will do this for us later when we quit R.
stopCluster(cls)

cls = makeCluster(2L, type = "PSOCK")


## This is the serial way of using lapply
lapply(x, seq)

## We can copy and paste it, and then convert it to parallel.
parLapply(cls, 1:4, seq)

## It gives us the same answer.

result = list()
for(i in seq_along(x)){
    result[[i]] = seq(x[[i]])
}
## It sent one group to each worker node, along with the function `seq`,  and asked it to evaluate it.
## Each workers evaluates `lapply(x_group, seq)` on their particular `x_group`, and then sends the result back to the manager.
## Once the manager has collected all the results from all the workers it returns the result.
## This is all overhead that the serial model doesn't have.


# Local:
ls(envir = globalenv())

# Same code called on each worker node:
clusterCall(cls, ls, envir = globalenv())

# `clusterCall` works just like `do.call`, only it calls the function on a cluster.

preprocess1 = function(x)
{
    tolower(x)
}

## a string, complete with a subliminal message.
strings = c("Ask questions", "If you don't understand.")

## It could look at the code for `preprocess2` and see that I use the function `civilize`, and somehow magically know that this is a function that I wrote, and that I actually mean to export and use it.
## If `parLapply` is that smart, then this should work, just like it did locally.
## If it doesn't, then it should return an error, saying it can't find the function `civilize`.  
## Make your predictions!
parLapply(cls, strings, preprocess2)

## It's not that smart, not yet anyways.
## This is the sort of thing I think about in my research, how to make the code smarter.

clusterExport(cls, "civilize")

## Now it's there:

clusterCall(cls, ls, envir = globalenv())


preprocess3 = function(x)
{
    result = tolower(x)
    stemDocument(result)
}

lapply(strings, preprocess3)

## I've put such a script in `preprocess.R`.
## Let's start fresh with a new cluster and see it in action.

stopCluster(cls)

cls = makeCluster(2L, type = "PSOCK")

clusterCall(cls, source, "preprocess.R")

## Now it all works great.

parLapply(cls, strings, preprocess3)


