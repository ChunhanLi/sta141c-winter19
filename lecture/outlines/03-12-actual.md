## Announcements

- We'll post solutions to HW5, but don't rely on them to do the peer review, because there are many possible valid solutions.
- I have a new SQLite database built for you.
    I'm in the process of zipping and transferring it.
    I plan to post it later today.
- Regarding grading- Homework 5 was harder, but worth less points on Canvas than the others.
    Homeworks 1-5 will all be worth the same amount, and Homework 6 will be worth 1/4 of that amount.
    We'll drop the lowest of homeworks 1-6.


## Project notes

- It can be frustrating and overwhelming to work with large data sets.
    They're rarely in the form you want, they're incomplete or have duplicates, and we often don't know exactly what things mean.
- You'll probably get going faster by starting small.
    Start by filtering the rows and columns to something more manageable than the entire data set.
- Remember to address specific, focused questions

Do the best with what you have.
When in doubt, use common sense and state your assumptions.
For example:

> We noted that the annual totals for `total_funding` in the `awards` table are less than the aggregate figures provided by the Congressional Budget Office (CBO).
> However, since 2008, the numbers consistently aggregate to about 80% of those of the CBO, so we've restricted our analysis to this time period.

## Questions

Will I curve?

Maybe. But only up :)

2nd participation score?

Yes. And Piazza counts.

I will put the SQLite database on the /scratch nodes, same place as the other data.

Extra office hour next week?
Yes, I'll announce.

Project due date Friday morning.

## Hadoop

```{bash}

hdfs dfs -ls

```


