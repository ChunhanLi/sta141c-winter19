- 

How do we calculate how large an array is?
Arrays are a generalization of matrices, so lets just think about matrices.

```{r}
n = 1000
p = 500
x = matrix(rnorm(n * p), nrow = n)

typeof(x)

# Expert knowledge!
bytes_per_double = 8

expected_size = n * p * bytes_per_double
```

Is the object the expected size?

```{r}
object.size(x)
```

Not exactly.
Question: Why not?
Because R has some memory overhead per object, a few bytes of metadata hanging out for every object.

Question: How large will it be if we store this in a general container, like a list?

```{r}
xl = lapply(x, identity)
object.size(xl)

as.numeric(object.size(xl) / object.size(x))
```

The list is 8 times bigger than the efficient matrix form.

Which one is faster?

```{r}
library(microbenchmark)
sum(x)
microbenchmark(sum(x))
microbenchmark(do.call(sum, xl))
```

Yes, we go from around 400 microseconds to 40 milliseconds, which means that the array form is 2 orders of magnitude faster.

For efficiency we like small objects, and fast code.

```{r}
object.size(1:1e10)
```

## Matrix

Statisticians, scientists, engineers, everyone loves matrices.
There are all kinds of special ones.
By using data structures that account for special structure in our data, we can increase speed and reduce memory usage.

For the next homework I will ask you to play around with sparse matrices.
Sparse matrices mean that most entries are zero.

I'll demonstrate the robust, recommended Matrix package.

```{r}
library(Matrix)

m = Matrix(1:10, nrow = 2)

class(m)
```

So what's a dgeMatrix?
We need to look up the help page for the class.

```{r}
?dgeMatrix # Nope

class?dgeMatrix
```

The help page says that this is a general class of dense matrix and lists many methods that are defined for this class.
