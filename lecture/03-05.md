Possible topics:

- profiling in R
- SQL
- how to give good peer feedback
- dash data repository - one possible output of your project is a refined data file.

Announcements:

- Nice job!
  This class in general, and HW5 in particular, was challenging for many.
  I'm proud of the effort you put in.


## Review

Last time we learned about performance monitoring.
If we're piping together several commands using pipes, then the __bottleneck__ is the process that is slowest, taking up close to 100% of 1 CPU.
The way to accelerate your program is to remove or accelerate the bottlenecks.

One way to profile a python script `foo.py` is to run the script with the `cProfile` module:

```{bash}
python3 -m cProfile foo.py
```


## Profiling

```{r}

qbenfords = log10(1 + 1/seq(9))
uniform = rep(1/9, length.out = 9)

kld = function(p, q)
{
    tmp = p * log(p / q)
    sum(tmp, na.rm = TRUE)
}

# Testing
kld(uniform, qbenfords)

kld(qbenfords, qbenfords)


# A single bootstrap
boot1 = function(size, p, q)
{
    # Using a factor handles the case when not all distinct values appear
    x = as.factor(seq_along(q))
    s = sample(x, size = size, replace = TRUE, prob = p)
    pstar = table(s) / size
    kld(pstar, q)
}

# Testing
boot1(100, uniform, qbenfords)


# Perform many bootstraps and return the quantiles
bootkld = function(n, p, q, reps = 1000, alpha = 0.05)
{
    a2 = alpha / 2
    results = replicate(reps, boot1(n, p, q))
    quantile(results, probs = c(a2, 1-a2))
}

# Testing
bootkld(1e4, uniform, qbenfords)
```

Now we can benchmark with `Rprof`.

This turns on the profiler inside R.
The profile looks at the call stack at regular intervals to see where the program is spending it's time.
In contrast to Python's deterministic profiler, this is random and based on sampling.

```{r}
Rprof()
```


- tryCatch
- logging
- on.exit
- variable arguments ...
- lazy evaluation
- test driven development
- DB streaming example
